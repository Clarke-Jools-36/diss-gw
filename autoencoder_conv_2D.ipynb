{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "fb99720b-a30b-4ca9-987e-ca158ba90d9e",
      "metadata": {
        "id": "fb99720b-a30b-4ca9-987e-ca158ba90d9e"
      },
      "outputs": [],
      "source": [
        "#!pip3 install tqdm\n",
        "#!pip3 install ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e35f315c-7968-45bf-b598-c73468a1bdbb",
      "metadata": {
        "id": "e35f315c-7968-45bf-b598-c73468a1bdbb"
      },
      "outputs": [],
      "source": [
        "#from ipywidgets import IProgress\n",
        "#!pip install tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccd218e2-c15f-44a0-bfb0-e986d2b51c02",
      "metadata": {
        "id": "ccd218e2-c15f-44a0-bfb0-e986d2b51c02"
      },
      "source": [
        "use terminal - ```igwn-keras2```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b79e92a5-35a9-4ff0-98ee-bec61dbbf7b2",
      "metadata": {
        "id": "b79e92a5-35a9-4ff0-98ee-bec61dbbf7b2"
      },
      "outputs": [],
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P gravity_spy https://github.com/Clarke-Jools-36/diss-gw/blob/main/blip_data/gravity_spy/Blip_strain.mat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3prK4rpwwf-",
        "outputId": "f866caeb-1053-4b45-ad16-225f3dde5c7f"
      },
      "id": "C3prK4rpwwf-",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-21 13:03:10--  https://github.com/Clarke-Jools-36/diss-gw/blob/main/blip_data/gravity_spy/Blip_strain.mat\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘gravity_spy/Blip_strain.mat.1’\n",
            "\n",
            "Blip_strain.mat.1       [ <=>                ] 140.79K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2022-12-21 13:03:11 (1.89 MB/s) - ‘gravity_spy/Blip_strain.mat.1’ saved [144166]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the data, form my github (temporary)"
      ],
      "metadata": {
        "id": "PBKQHWwG3Vip"
      },
      "id": "PBKQHWwG3Vip"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "440c2d3f-4fd8-476f-979e-b8839a440d13",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "440c2d3f-4fd8-476f-979e-b8839a440d13",
        "outputId": "40ea46c6-1920-4d7e-cbe4-2189fe20e18f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b11140014355>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#mat = scipy.io.loadmat('gravity_spy/Blip_strain.mat')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gravity_spy/Blip_strain.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#mat = scipy.io.loadmat('gravity_spy/Repeating_Blips_strain.mat')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \u001b[0;31m# converting the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_loadtxt_chunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mread_data\u001b[0;34m(chunk_size)\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m             \u001b[0;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m             \u001b[0;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mfloatconv\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'0x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromhex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0mtyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '<!DOCTYPE'"
          ]
        }
      ],
      "source": [
        "\n",
        "mat = scipy.io.loadmat('gravity_spy/Blip_strain.mat')\n",
        "#mat = np.loadtxt('gravity_spy/Blip_strain.mat') #depending on what versions of\n",
        "                                                  # which are installed \n",
        "                                                  #sometimes this fails\n",
        "\n",
        "\n",
        "mat[\"outData\"].shape\n",
        "n = len(mat[\"outData\"][:,0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###STFT"
      ],
      "metadata": {
        "id": "sm9REJny4KGK"
      },
      "id": "sm9REJny4KGK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is my short time fourier transform. I have looked through it and i think it is all ok, but i'd apreciate a second pair of eyes here sometime"
      ],
      "metadata": {
        "id": "viWX0JaQ3cyZ"
      },
      "id": "viWX0JaQ3cyZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2758d231-7ab6-434e-ae05-28516a76f48b",
      "metadata": {
        "id": "2758d231-7ab6-434e-ae05-28516a76f48b"
      },
      "outputs": [],
      "source": [
        "#BETTER SHORT TIME FOURIER TRANSFORM\n",
        "def better_stft(data, fs = 1024, fft_size = 32, overlap_fac = 0.8):\n",
        "\n",
        "    # fs = a scalar which is the sampling frequency of the data\n",
        "    #fft_size = the size of the fast fourier transform window [power of 2]\n",
        "    #overlap_fac = the overlap factor [0-1]\n",
        "\n",
        "\n",
        "    hop_size = np.int32(np.floor(fft_size * (1-overlap_fac)))\n",
        "    pad_end_size = fft_size          # the last segment can overlap the end of the data array by no more than one window size\n",
        "    total_segments = np.int32(np.ceil(len(data) / np.float32(hop_size)))\n",
        "    t_max = len(data) / np.float32(fs)\n",
        "\n",
        "    window = np.hanning(fft_size)  # our half cosine window\n",
        "    inner_pad = np.zeros(fft_size) # the zeros which will be used to double each segment size\n",
        "\n",
        "    proc = np.concatenate((data, np.zeros(pad_end_size)))              # the data to process\n",
        "    result = np.empty((total_segments, fft_size), dtype=np.float32)    # space to hold the result\n",
        "\n",
        "    for i in range(total_segments):                      # for each segment\n",
        "        current_hop = hop_size * i                        # figure out the current segment offset\n",
        "        segment = proc[current_hop:current_hop+fft_size]  # get the current segment\n",
        "        windowed = segment * window                       # multiply by the half cosine function\n",
        "        padded = np.append(windowed, inner_pad)           # add 0s to double the length of the data\n",
        "        spectrum = np.fft.fft(padded) / fft_size          # take the Fourier Transform and scale by the number of samples\n",
        "        autopower = np.abs(spectrum * np.conj(spectrum))  # find the autopower spectrum\n",
        "        result[i, :] = autopower[:fft_size]               # append to the results array\n",
        "\n",
        "    #result = 20*np.log10(result)          # scale to db\n",
        "    #result = np.clip(result,-85, -40)[:-(int(fft_size*0.15)),:].T   # clip values, and remove edge effects\n",
        "    \n",
        "    result = result[:-(int(fft_size*0.15)),:].T\n",
        "    return result\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets test out the function above with one wave from the data"
      ],
      "metadata": {
        "id": "k7qqnDDm3PQU"
      },
      "id": "k7qqnDDm3PQU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "724fb050-2a2b-4e0c-8476-bdc134ecf953",
      "metadata": {
        "id": "724fb050-2a2b-4e0c-8476-bdc134ecf953"
      },
      "outputs": [],
      "source": [
        "wave_number = 3\n",
        "# data = a numpy array containing the signal to be processed\n",
        "print(n)\n",
        "print( (int(n/4)-1) )\n",
        "random_offset = np.random.randint(0, high = (int(n/4)-1) ) #-1 is for security to prevent calling out of bounds\n",
        "    \n",
        "data = mat[\"outData\"][:,wave_number][random_offset:random_offset+int((3*n)/4)]\n",
        "\n",
        "plt.plot(data)\n",
        "plt.ylabel(\"strain\")\n",
        "plt.xlabel(\"time\")\n",
        "plt.figure()\n",
        "\n",
        "result = better_stft(data)\n",
        "img = plt.imshow(result, origin='lower', cmap='jet', interpolation='nearest', aspect='auto')\n",
        "plt.ylabel(\"freq Hz\")\n",
        "plt.xlabel(\"time\")\n",
        "\n",
        "plt.colorbar(label=\"dB\") #is dB correct here?? I'm not sure but its useful\n",
        "\n",
        "plt.show()\n",
        "\n",
        "result.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6cfc94b-633b-48db-a150-1db655ad4476",
      "metadata": {
        "id": "f6cfc94b-633b-48db-a150-1db655ad4476"
      },
      "outputs": [],
      "source": [
        "img_shape = result.shape\n",
        "img_size = img_shape[0]*img_shape[1]\n",
        "print(img_shape)\n",
        "print(img_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets split into test and train"
      ],
      "metadata": {
        "id": "ODsCBYhO3pLQ"
      },
      "id": "ODsCBYhO3pLQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dc81f88-c927-44ee-b61a-4d64f3a0665c",
      "metadata": {
        "id": "2dc81f88-c927-44ee-b61a-4d64f3a0665c"
      },
      "outputs": [],
      "source": [
        "test_train_ratio = 0.8\n",
        "\n",
        "x_train = np.zeros([int(mat[\"outData\"].shape[1]*test_train_ratio), result.shape[0]*result.shape[1]])\n",
        "x_test = np.zeros([int(mat[\"outData\"].shape[1]*(1-test_train_ratio))-1, result.shape[0]*result.shape[1]])\n",
        "\n",
        "print(f'{x_train.shape} {x_test.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "and the convert them all to stft "
      ],
      "metadata": {
        "id": "C61KCJGk34te"
      },
      "id": "C61KCJGk34te"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef734bee-c90f-4ff5-9040-28765df08d3d",
      "metadata": {
        "id": "ef734bee-c90f-4ff5-9040-28765df08d3d"
      },
      "outputs": [],
      "source": [
        "for i in np.arange(len(x_train)):\n",
        "    random_offset = np.random.randint(0, high = (int(n/4)-1) ) #-1 is for security to prevent calling out of bounds\n",
        "    #random_offset = (int(n/8)-1)\n",
        "    \n",
        "    wave_ = mat[\"outData\"][:,i][random_offset:random_offset+int((3*n)/4)]\n",
        "    \n",
        "    x_train[i] = better_stft(wave_).reshape((3968,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89a21a60-cacc-4ea7-9112-b4d75ee2a55a",
      "metadata": {
        "id": "89a21a60-cacc-4ea7-9112-b4d75ee2a55a"
      },
      "outputs": [],
      "source": [
        "for i in np.arange(len(x_test)):\n",
        "    random_offset = np.random.randint(0, high = (int(n/4)-1) ) #-1 is for security to prevent calling out of bounds\n",
        "    #random_offset = (int(n/8)-1)\n",
        "    \n",
        "    wave_ = mat[\"outData\"][:,i+len(x_train)][random_offset:random_offset+int((3*n)/4)]\n",
        "    \n",
        "    x_test[i] = better_stft(wave_).reshape((3968,))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lets plot them to make sure its all ok"
      ],
      "metadata": {
        "id": "b4wP-LM-3_p6"
      },
      "id": "b4wP-LM-3_p6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f416da41-730d-4869-914d-8e11bea479d2",
      "metadata": {
        "id": "f416da41-730d-4869-914d-8e11bea479d2"
      },
      "outputs": [],
      "source": [
        "n_ = 3  # How many digits we will display\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "for i in range(n_):\n",
        "    # Display original\n",
        "    ax = plt.subplot(2, n_, i + 1)\n",
        "    \n",
        "    img = plt.imshow(x_train[i].reshape(img_shape), origin='lower', cmap='jet', interpolation='nearest', aspect='auto')\n",
        "    plt.ylabel(\"freq / Hz\")\n",
        "    plt.xlabel(\"time / samples\")\n",
        "    plt.title(f\"Train {i}\")\n",
        "\n",
        "    plt.colorbar(label=\"dB\") #is dB correct here?? I'm not sure but its useful\n",
        "    plt.tight_layout()\n",
        "    \n",
        "    #ax.get_xaxis().set_visible(False)\n",
        "    #ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(2, n_, i + 1 + n_)\n",
        "    \n",
        "    img = plt.imshow(x_test[i].reshape(img_shape), origin='lower',interpolation='nearest', cmap='jet',  aspect='auto')\n",
        "    plt.ylabel(\"freq / Hz\")\n",
        "    plt.xlabel(\"time / samples\")\n",
        "    plt.title(f\"Test {i}\")\n",
        "\n",
        "    plt.colorbar(label=\"dB\") #is dB correct here?? I'm not sure but its useful\n",
        "    plt.tight_layout()\n",
        "    \n",
        "    #ax.get_xaxis().set_visible(False)\n",
        "    #ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0834803-17fd-476a-bddd-14a69c1735e3",
      "metadata": {
        "id": "b0834803-17fd-476a-bddd-14a69c1735e3"
      },
      "source": [
        "Check that these first 10 train and test images are different ^^"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Modelling"
      ],
      "metadata": {
        "id": "8vFdwpHd4EoP"
      },
      "id": "8vFdwpHd4EoP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the original dense layer model"
      ],
      "metadata": {
        "id": "DyW_REkP4Pur"
      },
      "id": "DyW_REkP4Pur"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c023253-ca59-4ba6-bc66-441134e38ba1",
      "metadata": {
        "id": "4c023253-ca59-4ba6-bc66-441134e38ba1"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\"\"\"\n",
        "# This is the size of our encoded representations\n",
        "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
        "\n",
        "# This is our input image\n",
        "input_img = keras.Input(shape=(img_size))  #1024 make it this! #####################################\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "decoded = layers.Dense(img_size, activation='sigmoid')(encoded)  #1024 make it this!####################\n",
        "\n",
        "# This model maps an input to its reconstruction\n",
        "autoencoder = keras.Model(input_img, decoded)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is my attempt at using conv2d, but I can't produce a model that will compile"
      ],
      "metadata": {
        "id": "et66n7yr4VeL"
      },
      "id": "et66n7yr4VeL"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "12a3a667-f32a-4d85-92f3-1dc3b237c55a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "12a3a667-f32a-4d85-92f3-1dc3b237c55a",
        "outputId": "996b2a70-1938-4d2e-bee0-80d3c7f907f6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7677ff27b079>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_shape_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimg_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#apparently it wants a 3d shape but that might be for rgb which these are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmax1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'img_shape' is not defined"
          ]
        }
      ],
      "source": [
        "img_shape_ = [img_shape[0], img_shape[1], 3] #apparently it wants a 3d shape but\n",
        "                                            # that might be for rgb which these\n",
        "                                            # are not\n",
        "\n",
        "inputs = keras.Input(shape = ())\n",
        "conv1 = layers.Conv2D(32, kernel_size = (5,5), strides = (1,1), activation = 'relu')(inputs)\n",
        "max1 = layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(conv1)\n",
        "conv2 = layers.Conv2D(64, (5,5), activation = 'relu')(max1)\n",
        "max2 = layers.MaxPooling2D(pool_size=(2,2))(conv2)\n",
        "flat = layers.Flatten()(max2)\n",
        "den1 = layers.Dense(100, activation = 'relu')(flat)\n",
        "decoded = layers.Dense(img_size, activation='sigmoid')(den1)\n",
        "\n",
        "# This model maps an input to its reconstruction\n",
        "autoencoder = keras.Model(input_img, decoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "potentially the kernel wantsa to be (5,y_max) so it searches the whole image at once, but thats to play with once it works.\n"
      ],
      "metadata": {
        "id": "_n6Q55UM6HBH"
      },
      "id": "_n6Q55UM6HBH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e3999d4-e8f1-4b69-919c-d4d2aa41c18c",
      "metadata": {
        "id": "5e3999d4-e8f1-4b69-919c-d4d2aa41c18c"
      },
      "outputs": [],
      "source": [
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec0bbdfc-7324-4332-b321-d86ed0d0828e",
      "metadata": {
        "id": "ec0bbdfc-7324-4332-b321-d86ed0d0828e"
      },
      "outputs": [],
      "source": [
        "x_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b35415f3-7765-410b-9b0f-eda2af3c80fc",
      "metadata": {
        "id": "b35415f3-7765-410b-9b0f-eda2af3c80fc"
      },
      "outputs": [],
      "source": [
        "print(max(x_train.flatten()) - min(x_train.flatten()))\n",
        "print(min(x_train.flatten()))\n",
        "\n",
        "plt.hist(x_train.flatten(), bins=30)\n",
        "plt.yscale('log')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Normailsation\n",
        "\n",
        "I have tried a few different types of normalisation, but i'm unsure which one to settle on"
      ],
      "metadata": {
        "id": "fwKISUnn4gYj"
      },
      "id": "fwKISUnn4gYj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ef49d18-54ac-422e-86c2-1809bd4505ba",
      "metadata": {
        "id": "6ef49d18-54ac-422e-86c2-1809bd4505ba"
      },
      "outputs": [],
      "source": [
        "### NORMALISATION ###\n",
        "\"\"\"\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "normaliserm = max(x_train.flatten()) - min(x_train.flatten())\n",
        "normaliserc = min(x_train.flatten())\n",
        "x_train = (x_train-normaliserc) / normaliserm\n",
        "x_test = (x_test-normaliserc) / normaliserm\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "normaliserm = np.amax(x_train, axis=0) - np.amin(x_train, axis=0)\n",
        "normaliserc = np.amin(x_train, axis=0)\n",
        "x_train = (x_train-normaliserc) / normaliserm\n",
        "x_test = (x_test-normaliserc) / normaliserm\n",
        "\"\"\"\n",
        "\n",
        "normaliserm = 0.004\n",
        "\n",
        "normaliserc = 0\n",
        "x_train = (x_train-normaliserc) / normaliserm\n",
        "x_test = (x_test-normaliserc) / normaliserm\n",
        "\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "x_train = x_train.reshape(-1, img_shape[0], img_shape[1], 1)\n",
        "x_test = x_test.reshape(-1, img_shape[0], img_shape[1], 1)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train"
      ],
      "metadata": {
        "id": "kmr6-_LK4rvY"
      },
      "id": "kmr6-_LK4rvY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe0af386-ade9-44c0-82f5-591eb55fc9f3",
      "metadata": {
        "id": "fe0af386-ade9-44c0-82f5-591eb55fc9f3"
      },
      "outputs": [],
      "source": [
        "history = autoencoder.fit(x_train, x_train,\n",
        "                epochs=100, #50\n",
        "                batch_size=256, #256\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f273f7c5-c462-4b2d-a071-49b7f6c37280",
      "metadata": {
        "id": "f273f7c5-c462-4b2d-a071-49b7f6c37280"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07480197-d31f-4f11-8863-a1a0e8b91f1f",
      "metadata": {
        "id": "07480197-d31f-4f11-8863-a1a0e8b91f1f"
      },
      "outputs": [],
      "source": [
        "decoded_imgs = autoencoder.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "903996fc-0bd5-4eee-9be9-98aae5046327",
      "metadata": {
        "id": "903996fc-0bd5-4eee-9be9-98aae5046327"
      },
      "outputs": [],
      "source": [
        "n_ = 3 # How many digits we will display\n",
        "offset = 0\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "for i in range(n_):\n",
        "    # Display original\n",
        "    ax = plt.subplot(3, n_, i + 1)\n",
        "    \n",
        "    img = plt.imshow(x_test[i+offset].reshape(img_shape), origin='lower', cmap='jet', interpolation='nearest', aspect='auto', vmin = 0, vmax = 1)\n",
        "    plt.ylabel(\"freq Hz\")\n",
        "    plt.xlabel(\"time\")\n",
        "    plt.title(f\"Test {i+offset}\")\n",
        "\n",
        "    plt.colorbar(label=\"dB\") #is dB correct here?? I'm not sure but its useful\n",
        "    plt.tight_layout()\n",
        "    \n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(3, n_, i + 1 + n_)\n",
        "    \n",
        "    img = plt.imshow(decoded_imgs[i+offset].reshape(img_shape), origin='lower',interpolation='nearest', cmap='jet',  aspect='auto', vmin = 0, vmax = 1)\n",
        "    plt.ylabel(\"freq Hz\")\n",
        "    plt.xlabel(\"time\")\n",
        "    plt.title(f\"Reconstruction {i+offset}\")\n",
        "\n",
        "    plt.colorbar(label=\"dB\") #is dB correct here?? I'm not sure but its useful\n",
        "    plt.tight_layout()\n",
        "    \n",
        "    # Display Diff\n",
        "    ax = plt.subplot(3, n_, i + 1 + 2*n_)\n",
        "    \n",
        "    img = plt.imshow((x_test[i+offset]-decoded_imgs[i+offset]).reshape(img_shape), origin='lower',interpolation='nearest', cmap='jet',  aspect='auto', vmin = 0, vmax = 1)\n",
        "    plt.ylabel(\"freq Hz\")\n",
        "    plt.xlabel(\"time\")\n",
        "    plt.title(f\"Difference {i+offset}\")\n",
        "\n",
        "    plt.colorbar(label=\"dB\") #is dB correct here?? I'm not sure but its useful\n",
        "    plt.tight_layout()\n",
        "    \n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8e5c714-03e9-498c-a824-d60992436aa4",
      "metadata": {
        "id": "e8e5c714-03e9-498c-a824-d60992436aa4"
      },
      "source": [
        "add all signals and should get a number thats even if noise, kai squared distribution statistically "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10bff2df-537e-4996-a66c-31b16a39973d",
      "metadata": {
        "id": "10bff2df-537e-4996-a66c-31b16a39973d"
      },
      "outputs": [],
      "source": [
        "sum_diff = np.zeros_like(decoded_imgs[:,1])\n",
        "\n",
        "for i, decoded in enumerate(decoded_imgs):\n",
        "    sum_diff[i] = np.sum(x_test[i]-decoded_imgs[i])\n",
        "\n",
        "sum_diff.shape\n",
        "#np.savetxt(f\"m_moving{normaliserm}.txt\", sum_diff)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5f09570-4757-4094-baae-809858840b5b",
      "metadata": {
        "id": "b5f09570-4757-4094-baae-809858840b5b"
      },
      "source": [
        "The better the performance, we should see the sum differnce near zero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bf90d7b-b677-4f7b-822c-0e237d05b4b8",
      "metadata": {
        "id": "5bf90d7b-b677-4f7b-822c-0e237d05b4b8"
      },
      "outputs": [],
      "source": [
        "plt.boxplot(sum_diff)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}